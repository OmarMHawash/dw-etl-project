{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## required libraries:\n",
    "# pip install pandas sqlalchemy PyMySQL\n",
    "\n",
    "## required data:\n",
    "# Requirements/FileDB.sql to be imported into the MySQL database\n",
    "\n",
    "# Develop an ETL to fill the tables in the designed Dimensional model in part \n",
    "## required functionality:\n",
    "# The ETL contains the following tasks. \n",
    "# ○ Extract the related data from the related tables to fill the first fact table \n",
    "# ○ Make sure to handle (even if the data is clean) \n",
    "# ■ Redundant data (if it exists) \n",
    "# ■ missing values \n",
    "# ○ Load the data into the (facts and dimensions tables) \n",
    "# ● Make sure to run the ETL with current data, then try to add some data (not \n",
    "# cleaned), to make sure the ETL is working well.\n",
    "# ● Try to use automation tools like (Airflow) (Bouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef049c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import & check\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e44f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mySQL setup\n",
    "username='root'\n",
    "password='rootuser'\n",
    "host='127.0.0.1'\n",
    "port='3306'\n",
    "\n",
    "databaseNameSource='sakila' \n",
    "databaseNameETL='rental_film_dw'\n",
    "\n",
    "# connection string format\n",
    "connectionStrSource=f\"mysql+pymysql://{username}:{password}@{host}:{port}/{databaseNameSource}\"\n",
    "engineSource = create_engine(connectionStrSource)\n",
    "\n",
    "# connection string format\n",
    "connectionStrETL=f\"mysql+pymysql://{username}:{password}@{host}:{port}/{databaseNameETL}\"\n",
    "engineETL = create_engine(connectionStrETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34240380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ETL process...\n",
      "Populating Dim_Date...\n",
      "Dim_Date populated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\4137083286.py:41: UserWarning: The provided table name 'Dim_Date' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dim_date_df.to_sql('Dim_Date', engineETL, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "# --- ETL Process ---\n",
    "\n",
    "print(\"Starting ETL process...\")\n",
    "\n",
    "# --- 1. Populate Dim_Date ---\n",
    "print(\"Populating Dim_Date...\")\n",
    "# Find min and max dates from relevant source tables (payment and rental)\n",
    "min_payment_date_query = \"SELECT MIN(payment_date) FROM payment\"\n",
    "max_payment_date_query = \"SELECT MAX(payment_date) FROM payment\"\n",
    "min_rental_date_query = \"SELECT MIN(rental_date) FROM rental\"\n",
    "max_rental_date_query = \"SELECT MAX(rental_date) FROM rental\"\n",
    "\n",
    "min_payment_date = pd.read_sql(min_payment_date_query, engineSource).iloc[0, 0].date()\n",
    "max_payment_date = pd.read_sql(max_payment_date_query, engineSource).iloc[0, 0].date()\n",
    "min_rental_date = pd.read_sql(min_rental_date_query, engineSource).iloc[0, 0].date()\n",
    "max_rental_date = pd.read_sql(max_rental_date_query, engineSource).iloc[0, 0].date()\n",
    "\n",
    "start_date = min(min_payment_date, min_rental_date)\n",
    "end_date = max(max_payment_date, max_rental_date)\n",
    "\n",
    "# Generate dates\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "dim_date_df = pd.DataFrame({\n",
    "    'date_key': date_range.strftime('%Y%m%d').astype(int),\n",
    "    'date': date_range.date,\n",
    "    'day_of_week': date_range.dayofweek + 1, # Monday=1, Sunday=7\n",
    "    'day_name': date_range.day_name(),\n",
    "    'day_of_month': date_range.day,\n",
    "    'day_of_year': date_range.dayofyear,\n",
    "    'week_of_year': date_range.isocalendar().week.astype(int),\n",
    "    'month': date_range.month,\n",
    "    'month_name': date_range.month_name(),\n",
    "    'quarter': date_range.quarter,\n",
    "    'year': date_range.year,\n",
    "    'fiscal_year': date_range.year,\n",
    "    'is_weekend': ((date_range.dayofweek == 5) | (date_range.dayofweek == 6))\n",
    "})\n",
    "\n",
    "# Load into Dim_Date\n",
    "try:\n",
    "    dim_date_df.to_sql('Dim_Date', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Date populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Date: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b8e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Dim_Staff...\n",
      "Dim_Staff populated successfully.\n",
      "Populating Dim_Film...\n",
      "Dim_Film populated successfully.\n",
      "Populating Dim_Store...\n",
      "Dim_Store populated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\2962746099.py:11: UserWarning: The provided table name 'Dim_Staff' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dim_staff_df.to_sql('Dim_Staff', engineETL, if_exists='append', index=False)\n",
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\2962746099.py:41: UserWarning: The provided table name 'Dim_Film' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dim_film_df.to_sql('Dim_Film', engineETL, if_exists='append', index=False)\n",
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\2962746099.py:65: UserWarning: The provided table name 'Dim_Store' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dim_store_df.to_sql('Dim_Store', engineETL, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Populate Dim_Staff ---\n",
    "print(\"Populating Dim_Staff...\")\n",
    "staff_query = \"SELECT staff_id, first_name, last_name, email, username FROM staff\"\n",
    "dim_staff_df = pd.read_sql(staff_query, engineSource)\n",
    "\n",
    "# Handle missing values if any (email can be NULL)\n",
    "dim_staff_df['email'] = dim_staff_df['email'].fillna('') # Replace None with empty string\n",
    "\n",
    "# Load into Dim_Staff\n",
    "try:\n",
    "    dim_staff_df.to_sql('Dim_Staff', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Staff populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Staff: {e}\")\n",
    "\n",
    "# --- 3. Populate Dim_Film ---\n",
    "print(\"Populating Dim_Film...\")\n",
    "film_query = \"\"\"\n",
    "SELECT\n",
    "    film_id,\n",
    "    title,\n",
    "    description,\n",
    "    release_year,\n",
    "    language_id,\n",
    "    original_language_id,\n",
    "    rental_duration,\n",
    "    rental_rate,\n",
    "    length,\n",
    "    replacement_cost,\n",
    "    rating,\n",
    "    special_features\n",
    "FROM film\n",
    "\"\"\"\n",
    "dim_film_df = pd.read_sql(film_query, engineSource)\n",
    "\n",
    "# Handle missing values for description and special_features if any\n",
    "dim_film_df['description'] = dim_film_df['description'].fillna('')\n",
    "dim_film_df['special_features'] = dim_film_df['special_features'].fillna('')\n",
    "\n",
    "# Load into Dim_Film\n",
    "try:\n",
    "    dim_film_df.to_sql('Dim_Film', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Film populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Film: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cae717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Populate Dim_Store ---\n",
    "print(\"Populating Dim_Store...\")\n",
    "store_query = \"\"\"\n",
    "SELECT\n",
    "    s.store_id,\n",
    "    s.address_id\n",
    "FROM store s\n",
    "\"\"\"\n",
    "dim_store_df = pd.read_sql(store_query, engineSource)\n",
    "\n",
    "# Load into Dim_Store\n",
    "try:\n",
    "    dim_store_df.to_sql('Dim_Store', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Store populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Store: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40249ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Dim_Rent...\n",
      "Dim_Rent populated successfully.\n",
      "Fetching surrogate keys...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\382073140.py:19: UserWarning: The provided table name 'Dim_Rent' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dim_rent_df.to_sql('Dim_Rent', engineETL, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Populate Dim_Rent ---\n",
    "print(\"Populating Dim_Rent...\")\n",
    "rent_query = \"\"\"\n",
    "SELECT\n",
    "    rental_id,\n",
    "    inventory_id,\n",
    "    customer_id,\n",
    "    rental_date,\n",
    "    return_date\n",
    "FROM rental\n",
    "\"\"\"\n",
    "dim_rent_df = pd.read_sql(rent_query, engineSource)\n",
    "\n",
    "# Handle missing values (return_date can be NULL)\n",
    "dim_rent_df['return_date'] = dim_rent_df['return_date'].fillna(pd.NaT) # Use NaT for missing datetime\n",
    "\n",
    "# Load into Dim_Rent\n",
    "try:\n",
    "    dim_rent_df.to_sql('Dim_Rent', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Rent populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Rent: {e}\")\n",
    "\n",
    "print(\"Fetching surrogate keys...\")\n",
    "# Dim_Date - date_key is explicitly generated and known\n",
    "dim_date_map = dim_date_df[['date', 'date_key']].set_index('date').to_dict()['date_key']\n",
    "\n",
    "# Dim_Staff\n",
    "staff_surrogate_map_query = \"SELECT staff_id, staff_key FROM Dim_Staff\"\n",
    "staff_surrogate_map_df = pd.read_sql(staff_surrogate_map_query, engineETL)\n",
    "staff_surrogate_map = staff_surrogate_map_df.set_index('staff_id')['staff_key'].to_dict()\n",
    "\n",
    "# Dim_Film\n",
    "film_surrogate_map_query = \"SELECT film_id, film_key FROM Dim_Film\"\n",
    "film_surrogate_map_df = pd.read_sql(film_surrogate_map_query, engineETL)\n",
    "film_surrogate_map = film_surrogate_map_df.set_index('film_id')['film_key'].to_dict()\n",
    "\n",
    "# Dim_Store\n",
    "store_surrogate_map_query = \"SELECT store_id, store_key FROM Dim_Store\"\n",
    "store_surrogate_map_df = pd.read_sql(store_surrogate_map_query, engineETL)\n",
    "store_surrogate_map = store_surrogate_map_df.set_index('store_id')['store_key'].to_dict()\n",
    "\n",
    "# Dim_Rent\n",
    "rent_surrogate_map_query = \"SELECT rental_id, rent_key FROM Dim_Rent\"\n",
    "rent_surrogate_map_df = pd.read_sql(rent_surrogate_map_query, engineETL)\n",
    "rent_surrogate_map = rent_surrogate_map_df.set_index('rental_id')['rent_key'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871aefaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Dim_Rent...\n",
      "Error populating Dim_Rent: (pymysql.err.IntegrityError) (1062, \"Duplicate entry '1' for key 'dim_rent.rental_id'\")\n",
      "[SQL: INSERT INTO `Dim_Rent` (rental_id, inventory_id, customer_id, rental_date, return_date) VALUES (%(rental_id)s, %(inventory_id)s, %(customer_id)s, %(rental_date)s, %(return_date)s)]\n",
      "[parameters: [{'rental_id': 1, 'inventory_id': 367, 'customer_id': 130, 'rental_date': datetime.datetime(2005, 5, 24, 22, 53, 30), 'return_date': datetime.datetime(2005, 5, 26, 22, 4, 30)}, {'rental_id': 2, 'inventory_id': 1525, 'customer_id': 459, 'rental_date': datetime.datetime(2005, 5, 24, 22, 54, 33), 'return_date': datetime.datetime(2005, 5, 28, 19, 40, 33)}, {'rental_id': 3, 'inventory_id': 1711, 'customer_id': 408, 'rental_date': datetime.datetime(2005, 5, 24, 23, 3, 39), 'return_date': datetime.datetime(2005, 6, 1, 22, 12, 39)}, {'rental_id': 4, 'inventory_id': 2452, 'customer_id': 333, 'rental_date': datetime.datetime(2005, 5, 24, 23, 4, 41), 'return_date': datetime.datetime(2005, 6, 3, 1, 43, 41)}, {'rental_id': 5, 'inventory_id': 2079, 'customer_id': 222, 'rental_date': datetime.datetime(2005, 5, 24, 23, 5, 21), 'return_date': datetime.datetime(2005, 6, 2, 4, 33, 21)}, {'rental_id': 6, 'inventory_id': 2792, 'customer_id': 549, 'rental_date': datetime.datetime(2005, 5, 24, 23, 8, 7), 'return_date': datetime.datetime(2005, 5, 27, 1, 32, 7)}, {'rental_id': 7, 'inventory_id': 3995, 'customer_id': 269, 'rental_date': datetime.datetime(2005, 5, 24, 23, 11, 53), 'return_date': datetime.datetime(2005, 5, 29, 20, 34, 53)}, {'rental_id': 8, 'inventory_id': 2346, 'customer_id': 239, 'rental_date': datetime.datetime(2005, 5, 24, 23, 31, 46), 'return_date': datetime.datetime(2005, 5, 27, 23, 33, 46)}  ... displaying 10 of 16044 total bound parameter sets ...  {'rental_id': 16048, 'inventory_id': 2019, 'customer_id': 103, 'rental_date': datetime.datetime(2005, 8, 23, 22, 43, 7), 'return_date': datetime.datetime(2005, 8, 31, 21, 33, 7)}, {'rental_id': 16049, 'inventory_id': 2666, 'customer_id': 393, 'rental_date': datetime.datetime(2005, 8, 23, 22, 50, 12), 'return_date': datetime.datetime(2005, 8, 30, 1, 1, 12)}]]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Fetching surrogate keys...\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Populate Dim_Rent ---\n",
    "print(\"Populating Dim_Rent...\")\n",
    "rent_query = \"\"\"\n",
    "SELECT\n",
    "    rental_id,\n",
    "    inventory_id,\n",
    "    customer_id,\n",
    "    rental_date,\n",
    "    return_date\n",
    "FROM rental\n",
    "\"\"\"\n",
    "dim_rent_df = pd.read_sql(rent_query, engineSource)\n",
    "\n",
    "# Handle missing values (return_date can be NULL)\n",
    "dim_rent_df['return_date'] = dim_rent_df['return_date'].fillna(pd.NaT) # Use NaT for missing datetime\n",
    "\n",
    "# Load into Dim_Rent\n",
    "try:\n",
    "    dim_rent_df.to_sql('Dim_Rent', engineETL, if_exists='append', index=False)\n",
    "    print(\"Dim_Rent populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Dim_Rent: {e}\")\n",
    "\n",
    "print(\"Fetching surrogate keys...\")\n",
    "# Dim_Date - date_key is explicitly generated and known\n",
    "dim_date_map = dim_date_df[['date', 'date_key']].set_index('date').to_dict()['date_key']\n",
    "\n",
    "# Dim_Staff\n",
    "staff_surrogate_map_query = \"SELECT staff_id, staff_key FROM Dim_Staff\"\n",
    "staff_surrogate_map_df = pd.read_sql(staff_surrogate_map_query, engineETL)\n",
    "staff_surrogate_map = staff_surrogate_map_df.set_index('staff_id')['staff_key'].to_dict()\n",
    "\n",
    "# Dim_Film\n",
    "film_surrogate_map_query = \"SELECT film_id, film_key FROM Dim_Film\"\n",
    "film_surrogate_map_df = pd.read_sql(film_surrogate_map_query, engineETL)\n",
    "film_surrogate_map = film_surrogate_map_df.set_index('film_id')['film_key'].to_dict()\n",
    "\n",
    "# Dim_Store\n",
    "store_surrogate_map_query = \"SELECT store_id, store_key FROM Dim_Store\"\n",
    "store_surrogate_map_df = pd.read_sql(store_surrogate_map_query, engineETL)\n",
    "store_surrogate_map = store_surrogate_map_df.set_index('store_id')['store_key'].to_dict()\n",
    "\n",
    "# Dim_Rent\n",
    "rent_surrogate_map_query = \"SELECT rental_id, rent_key FROM Dim_Rent\"\n",
    "rent_surrogate_map_df = pd.read_sql(rent_surrogate_map_query, engineETL)\n",
    "rent_surrogate_map = rent_surrogate_map_df.set_index('rental_id')['rent_key'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Fact_Monthly_Payment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\596990762.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fact_monthly_payment_final_df.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact_Monthly_Payment populated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\596990762.py:56: UserWarning: The provided table name 'Fact_Monthly_Payment' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  fact_monthly_payment_final_df.to_sql('Fact_Monthly_Payment', engineETL, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Populate Fact_Monthly_Payment ---\n",
    "print(\"Populating Fact_Monthly_Payment...\")\n",
    "payment_fact_query = \"\"\"\n",
    "SELECT\n",
    "    p.payment_date,\n",
    "    p.staff_id,\n",
    "    p.rental_id,\n",
    "    p.amount\n",
    "FROM payment p\n",
    "\"\"\"\n",
    "fact_monthly_payment_df = pd.read_sql(payment_fact_query, engineSource)\n",
    "\n",
    "# Transform: Aggregate and map surrogate keys\n",
    "# Extract month for aggregation\n",
    "fact_monthly_payment_df['payment_month_start'] = fact_monthly_payment_df['payment_date'].dt.to_period('M').dt.start_time\n",
    "\n",
    "# First, ensure all necessary columns are present for grouping\n",
    "fact_monthly_payment_df['payment_date_only'] = fact_monthly_payment_df['payment_date'].dt.date\n",
    "\n",
    "fact_monthly_payment_agg = fact_monthly_payment_df.groupby([\n",
    "    'payment_date_only', 'staff_id', 'rental_id'\n",
    "]).agg(\n",
    "    payment_amount=('amount', 'sum'),\n",
    "    payment_count=('amount', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Map date_key, staff_key, rent_key\n",
    "fact_monthly_payment_agg['date_key'] = fact_monthly_payment_agg['payment_date_only'].map(dim_date_map)\n",
    "fact_monthly_payment_agg['staff_key'] = fact_monthly_payment_agg['staff_id'].map(staff_surrogate_map)\n",
    "fact_monthly_payment_agg['rent_key'] = fact_monthly_payment_agg['rental_id'].map(rent_surrogate_map)\n",
    "\n",
    "# Select relevant columns for the fact table\n",
    "fact_monthly_payment_final_df = fact_monthly_payment_agg[[\n",
    "    'date_key', 'staff_key', 'rent_key', 'payment_amount', 'payment_count'\n",
    "]]\n",
    "\n",
    "# Handle potential missing keys if any (shouldn't happen with correct joins/maps)\n",
    "fact_monthly_payment_final_df.dropna(inplace=True)\n",
    "fact_monthly_payment_final_df = fact_monthly_payment_final_df.astype({\n",
    "    'date_key': int,\n",
    "    'staff_key': int,\n",
    "    'rent_key': int\n",
    "})\n",
    "\n",
    "# Load into Fact_Monthly_Payment\n",
    "try:\n",
    "    fact_monthly_payment_final_df.to_sql('Fact_Monthly_Payment', engineETL, if_exists='append', index=False)\n",
    "    print(\"Fact_Monthly_Payment populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Fact_Monthly_Payment: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a9c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\16269331.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fact_daily_inventory_final_df.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating Fact_Daily_Inventory...\n",
      "Fact_Daily_Inventory populated successfully.\n",
      "ETL process completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UnclePC\\AppData\\Local\\Temp\\ipykernel_13244\\16269331.py:51: UserWarning: The provided table name 'Fact_Daily_Inventory' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  fact_daily_inventory_final_df.to_sql('Fact_Daily_Inventory', engineETL, if_exists='append', index=False)\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Populate Fact_Daily_Inventory ---\n",
    "print(\"Populating Fact_Daily_Inventory...\")\n",
    "\n",
    "# Get distinct inventory items with their film and store IDs\n",
    "inventory_query = \"SELECT inventory_id, film_id, store_id FROM inventory\"\n",
    "source_inventory_df = pd.read_sql(inventory_query, engineSource)\n",
    "\n",
    "# Group by film_id and store_id to get inventory count for each film-store combination\n",
    "daily_inventory_agg = source_inventory_df.groupby(['film_id', 'store_id']).agg(\n",
    "    inventory_count=('inventory_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Get all unique dates from Dim_Date\n",
    "all_dates_df = pd.read_sql(\"SELECT date, date_key FROM Dim_Date\", engineETL)\n",
    "\n",
    "# Create a Cartesian product of daily_inventory_agg and all_dates_df\n",
    "fact_daily_inventory_df = pd.merge(daily_inventory_agg.assign(key=1), all_dates_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "\n",
    "# Map surrogate keys\n",
    "fact_daily_inventory_df['film_key'] = fact_daily_inventory_df['film_id'].map(film_surrogate_map)\n",
    "fact_daily_inventory_df['store_key'] = fact_daily_inventory_df['store_id'].map(store_surrogate_map)\n",
    "\n",
    "# Select and rename columns for the fact table\n",
    "fact_daily_inventory_final_df = fact_daily_inventory_df[[\n",
    "    'date_key', 'film_key', 'store_key', 'inventory_count'\n",
    "]]\n",
    "\n",
    "# Handle potential missing keys\n",
    "fact_daily_inventory_final_df.dropna(inplace=True)\n",
    "fact_daily_inventory_final_df = fact_daily_inventory_final_df.astype({\n",
    "    'date_key': int,\n",
    "    'film_key': int,\n",
    "    'store_key': int\n",
    "})\n",
    "\n",
    "# Load into Fact_Daily_Inventory\n",
    "try:\n",
    "    fact_daily_inventory_final_df.to_sql('Fact_Daily_Inventory', engineETL, if_exists='append', index=False)\n",
    "    print(\"Fact_Daily_Inventory populated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error populating Fact_Daily_Inventory: {e}\")\n",
    "\n",
    "print(\"ETL process completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
